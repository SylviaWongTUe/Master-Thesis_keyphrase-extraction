{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:01.067275Z","iopub.status.busy":"2023-07-26T14:33:01.066834Z","iopub.status.idle":"2023-07-26T14:33:20.477269Z","shell.execute_reply":"2023-07-26T14:33:20.476034Z","shell.execute_reply.started":"2023-07-26T14:33:01.067226Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install torch seqeval datasets evaluate accelerate peft transformers==4.28.0 --quiet"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:46.219990Z","iopub.status.busy":"2023-07-26T14:33:46.219597Z","iopub.status.idle":"2023-07-26T14:33:50.334990Z","shell.execute_reply":"2023-07-26T14:33:50.333891Z","shell.execute_reply.started":"2023-07-26T14:33:46.219959Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","key= user_secrets.get_secret(\"wandb\")\n","wandb.login(key=key)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:50.336984Z","iopub.status.busy":"2023-07-26T14:33:50.336348Z","iopub.status.idle":"2023-07-26T14:33:53.652522Z","shell.execute_reply":"2023-07-26T14:33:53.651111Z","shell.execute_reply.started":"2023-07-26T14:33:50.336952Z"},"executionInfo":{"elapsed":3801,"status":"ok","timestamp":1686164300622,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"gKEiDWaFSlWh","trusted":true},"outputs":[],"source":["import torch\n","import pandas as pd\n","import pickle"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:53.655388Z","iopub.status.busy":"2023-07-26T14:33:53.654307Z","iopub.status.idle":"2023-07-26T14:33:53.661460Z","shell.execute_reply":"2023-07-26T14:33:53.660238Z","shell.execute_reply.started":"2023-07-26T14:33:53.655334Z"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1686164378240,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"Xegkv9NfofYz","trusted":true},"outputs":[],"source":["input_path='/kaggle/Input/'\n","output_path='/kaggle/working/'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:53.663888Z","iopub.status.busy":"2023-07-26T14:33:53.663369Z","iopub.status.idle":"2023-07-26T14:33:53.676567Z","shell.execute_reply":"2023-07-26T14:33:53.675464Z","shell.execute_reply.started":"2023-07-26T14:33:53.663843Z"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1686164303883,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"Hk40GxMW_tOa","trusted":true},"outputs":[],"source":["label_list= ['O', 'B-TSK','I-TSK','B-MTD','I-MTD','B-DST','I-DST']"]},{"cell_type":"markdown","metadata":{"id":"q8PQ13P1oYpI"},"source":["# Dataset Preparation"]},{"cell_type":"markdown","metadata":{"id":"V4exMwiIDlaj"},"source":["## Load dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:53.679502Z","iopub.status.busy":"2023-07-26T14:33:53.679034Z","iopub.status.idle":"2023-07-26T14:33:56.397020Z","shell.execute_reply":"2023-07-26T14:33:56.395845Z","shell.execute_reply.started":"2023-07-26T14:33:53.679458Z"},"executionInfo":{"elapsed":5126,"status":"ok","timestamp":1686163682484,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"TQAaS68prLph","outputId":"2002833c-6f9b-4cfa-d7f3-9c1c746a2acc","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentences</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[[document, :, Deep, Label, Distribution, Lear...</td>\n","      <td>[[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[[In, this, work, we, explore, recent, advance...</td>\n","      <td>[[O, O, O, O, O, O, O, O, B-MTD, I-MTD, I-MTD,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[Bridging, Saliency, Detection, to, Weakly, S...</td>\n","      <td>[[B-TSK, I-TSK, I-TSK, O, B-TSK, I-TSK, I-TSK,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[document, :, The, IBM, 2016, English, Conver...</td>\n","      <td>[[O, O, O, B-TSK, I-TSK, I-TSK, I-TSK, I-TSK, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[document, :, Rethinking, the, Inception, Arc...</td>\n","      <td>[[O, O, O, O, B-MTD, I-MTD, O, B-TSK, I-TSK], ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>[[document, :, Invertible, Conditional, GANs, ...</td>\n","      <td>[[O, O, B-MTD, I-MTD, I-MTD, O, B-TSK, I-TSK],...</td>\n","    </tr>\n","    <tr>\n","      <th>434</th>\n","      <td>[[Asymmetric, Tri, -, training, for, Unsupervi...</td>\n","      <td>[[B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I-TSK,...</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>[[A, Convolutional, Encoder, Model, for, Neura...</td>\n","      <td>[[O, B-MTD, I-MTD, I-MTD, O, B-TSK, I-TSK, I-T...</td>\n","    </tr>\n","    <tr>\n","      <th>436</th>\n","      <td>[[document, :, Learning, to, Compare, :, Relat...</td>\n","      <td>[[O, O, B-TSK, O, O, O, B-MTD, I-MTD, O, O, B-...</td>\n","    </tr>\n","    <tr>\n","      <th>437</th>\n","      <td>[[document, :, EAST, :, An, Efficient, and, Ac...</td>\n","      <td>[[O, O, B-MTD, I-MTD, O, B-MTD, O, B-MTD, I-MT...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>438 rows × 2 columns</p>\n","</div>"],"text/plain":["                                             sentences  \\\n","0    [[document, :, Deep, Label, Distribution, Lear...   \n","1    [[In, this, work, we, explore, recent, advance...   \n","2    [[Bridging, Saliency, Detection, to, Weakly, S...   \n","3    [[document, :, The, IBM, 2016, English, Conver...   \n","4    [[document, :, Rethinking, the, Inception, Arc...   \n","..                                                 ...   \n","433  [[document, :, Invertible, Conditional, GANs, ...   \n","434  [[Asymmetric, Tri, -, training, for, Unsupervi...   \n","435  [[A, Convolutional, Encoder, Model, for, Neura...   \n","436  [[document, :, Learning, to, Compare, :, Relat...   \n","437  [[document, :, EAST, :, An, Efficient, and, Ac...   \n","\n","                                                  tags  \n","0    [[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, ...  \n","1    [[O, O, O, O, O, O, O, O, B-MTD, I-MTD, I-MTD,...  \n","2    [[B-TSK, I-TSK, I-TSK, O, B-TSK, I-TSK, I-TSK,...  \n","3    [[O, O, O, B-TSK, I-TSK, I-TSK, I-TSK, I-TSK, ...  \n","4    [[O, O, O, O, B-MTD, I-MTD, O, B-TSK, I-TSK], ...  \n","..                                                 ...  \n","433  [[O, O, B-MTD, I-MTD, I-MTD, O, B-TSK, I-TSK],...  \n","434  [[B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I-TSK,...  \n","435  [[O, B-MTD, I-MTD, I-MTD, O, B-TSK, I-TSK, I-T...  \n","436  [[O, O, B-TSK, O, O, O, B-MTD, I-MTD, O, O, B-...  \n","437  [[O, O, B-MTD, I-MTD, O, B-MTD, O, B-MTD, I-MT...  \n","\n","[438 rows x 2 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["with open(input_path+'Data/df_scirex.pkl', 'rb') as file:\n","    data=pickle.load(file)\n","data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:56.399559Z","iopub.status.busy":"2023-07-26T14:33:56.399084Z","iopub.status.idle":"2023-07-26T14:33:56.522557Z","shell.execute_reply":"2023-07-26T14:33:56.521379Z","shell.execute_reply.started":"2023-07-26T14:33:56.399513Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentences</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[[document, :, Deep, Label, Distribution, Lear...</td>\n","      <td>[[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           sentences  \\\n","0  [[document, :, Deep, Label, Distribution, Lear...   \n","\n","                                                tags  \n","0  [[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, ...  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data=data.iloc[0:1,:]\n","data"]},{"cell_type":"markdown","metadata":{"id":"4vs0GPlbniHn"},"source":["## Change the format"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:56.528434Z","iopub.status.busy":"2023-07-26T14:33:56.528026Z","iopub.status.idle":"2023-07-26T14:33:56.578053Z","shell.execute_reply":"2023-07-26T14:33:56.576854Z","shell.execute_reply.started":"2023-07-26T14:33:56.528400Z"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1686163682484,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"vu5UH5LfGhQx","outputId":"73918d4b-5a7d-4073-9676-c89c20931702","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentences</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[document, :, Deep, Label, Distribution, Learn...</td>\n","      <td>[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[Convolutional, Neural, Networks, (, ConvNets,...</td>\n","      <td>[B-MTD, I-MTD, I-MTD, I-MTD, I-MTD, I-MTD, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[A, large, labeled, training, set, is, one, of...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[However, ,, it, is, difficult, to, collect, s...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[Fortunately, ,, there, is, ambiguous, informa...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>606</th>\n","      <td>[{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>607</th>\n","      <td>[D, degree, from, Deakin, University, ,, Austr...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>[He, joined, the, School, of, Computer, Scienc...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>[He, has, authored, over, 50, refereed, papers...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>[His, research, interests, include, pattern, r...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>611 rows × 2 columns</p>\n","</div>"],"text/plain":["                                             sentences  \\\n","0    [document, :, Deep, Label, Distribution, Learn...   \n","1    [Convolutional, Neural, Networks, (, ConvNets,...   \n","2    [A, large, labeled, training, set, is, one, of...   \n","3    [However, ,, it, is, difficult, to, collect, s...   \n","4    [Fortunately, ,, there, is, ambiguous, informa...   \n","..                                                 ...   \n","606  [{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...   \n","607  [D, degree, from, Deakin, University, ,, Austr...   \n","608  [He, joined, the, School, of, Computer, Scienc...   \n","609  [He, has, authored, over, 50, refereed, papers...   \n","610  [His, research, interests, include, pattern, r...   \n","\n","                                                  tags  \n","0    [O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I...  \n","1    [B-MTD, I-MTD, I-MTD, I-MTD, I-MTD, I-MTD, O, ...  \n","2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n","3    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","4    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","..                                                 ...  \n","606  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","607                     [O, O, O, O, O, O, O, O, O, O]  \n","608  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","609  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","610         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n","\n","[611 rows x 2 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data=data.explode(['sentences','tags']).reset_index(drop=True)\n","data"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:56.580512Z","iopub.status.busy":"2023-07-26T14:33:56.580048Z","iopub.status.idle":"2023-07-26T14:33:56.850061Z","shell.execute_reply":"2023-07-26T14:33:56.848693Z","shell.execute_reply.started":"2023-07-26T14:33:56.580472Z"},"executionInfo":{"elapsed":35745,"status":"ok","timestamp":1686163719817,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"j7jJXiNDI4wy","outputId":"9dab3f89-a2e5-475d-f035-b192347eddef","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentences</th>\n","      <th>tags</th>\n","      <th>ner_tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[document, :, Deep, Label, Distribution, Learn...</td>\n","      <td>[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I...</td>\n","      <td>[0, 0, 3, 4, 4, 4, 0, 1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[Convolutional, Neural, Networks, (, ConvNets,...</td>\n","      <td>[B-MTD, I-MTD, I-MTD, I-MTD, I-MTD, I-MTD, O, ...</td>\n","      <td>[3, 4, 4, 4, 4, 4, 0, 0, 0, 1, 2, 0, 0, 1, 2, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[A, large, labeled, training, set, is, one, of...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[However, ,, it, is, difficult, to, collect, s...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[Fortunately, ,, there, is, ambiguous, informa...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>606</th>\n","      <td>[{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>607</th>\n","      <td>[D, degree, from, Deakin, University, ,, Austr...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>[He, joined, the, School, of, Computer, Scienc...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>[He, has, authored, over, 50, refereed, papers...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>[His, research, interests, include, pattern, r...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>611 rows × 3 columns</p>\n","</div>"],"text/plain":["                                             sentences  \\\n","0    [document, :, Deep, Label, Distribution, Learn...   \n","1    [Convolutional, Neural, Networks, (, ConvNets,...   \n","2    [A, large, labeled, training, set, is, one, of...   \n","3    [However, ,, it, is, difficult, to, collect, s...   \n","4    [Fortunately, ,, there, is, ambiguous, informa...   \n","..                                                 ...   \n","606  [{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...   \n","607  [D, degree, from, Deakin, University, ,, Austr...   \n","608  [He, joined, the, School, of, Computer, Scienc...   \n","609  [He, has, authored, over, 50, refereed, papers...   \n","610  [His, research, interests, include, pattern, r...   \n","\n","                                                  tags  \\\n","0    [O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I...   \n","1    [B-MTD, I-MTD, I-MTD, I-MTD, I-MTD, I-MTD, O, ...   \n","2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n","3    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","4    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","..                                                 ...   \n","606  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","607                     [O, O, O, O, O, O, O, O, O, O]   \n","608  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","609  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","610         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n","\n","                                              ner_tags  \n","0                          [0, 0, 3, 4, 4, 4, 0, 1, 2]  \n","1    [3, 4, 4, 4, 4, 4, 0, 0, 0, 1, 2, 0, 0, 1, 2, ...  \n","2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","..                                                 ...  \n","606  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","607                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","608  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","609  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","610         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","\n","[611 rows x 3 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data['ner_tags'] = pd.Series(dtype='object')\n","for i,item in enumerate(data.tags):\n","    ner_list=[]\n","    for tag in item:\n","        for j,label in enumerate(label_list):\n","            if tag==label:\n","                ner_list.append(j)\n","    data['ner_tags'][i]=ner_list\n","data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:56.853136Z","iopub.status.busy":"2023-07-26T14:33:56.851868Z","iopub.status.idle":"2023-07-26T14:33:56.899887Z","shell.execute_reply":"2023-07-26T14:33:56.898414Z","shell.execute_reply.started":"2023-07-26T14:33:56.853085Z"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1686163721650,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"LbLZ-kNwtvRj","outputId":"936db98f-2421-46e8-d2fe-901eaed54a4c","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentences</th>\n","      <th>tags</th>\n","      <th>ner_tags</th>\n","      <th>tokens</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[document, :, Deep, Label, Distribution, Learn...</td>\n","      <td>[O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I...</td>\n","      <td>[0, 0, 3, 4, 4, 4, 0, 1, 2]</td>\n","      <td>[document, :, Deep, Label, Distribution, Learn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[Convolutional, Neural, Networks, (, ConvNets,...</td>\n","      <td>[B-MTD, I-MTD, I-MTD, I-MTD, I-MTD, I-MTD, O, ...</td>\n","      <td>[3, 4, 4, 4, 4, 4, 0, 0, 0, 1, 2, 0, 0, 1, 2, ...</td>\n","      <td>[Convolutional, Neural, Networks, (, ConvNets,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[A, large, labeled, training, set, is, one, of...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[A, large, labeled, training, set, is, one, of...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[However, ,, it, is, difficult, to, collect, s...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[However, ,, it, is, difficult, to, collect, s...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[Fortunately, ,, there, is, ambiguous, informa...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[Fortunately, ,, there, is, ambiguous, informa...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>606</th>\n","      <td>[{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...</td>\n","      <td>606</td>\n","    </tr>\n","    <tr>\n","      <th>607</th>\n","      <td>[D, degree, from, Deakin, University, ,, Austr...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[D, degree, from, Deakin, University, ,, Austr...</td>\n","      <td>607</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>[He, joined, the, School, of, Computer, Scienc...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[He, joined, the, School, of, Computer, Scienc...</td>\n","      <td>608</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>[He, has, authored, over, 50, refereed, papers...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[He, has, authored, over, 50, refereed, papers...</td>\n","      <td>609</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>[His, research, interests, include, pattern, r...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[His, research, interests, include, pattern, r...</td>\n","      <td>610</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>611 rows × 5 columns</p>\n","</div>"],"text/plain":["                                             sentences  \\\n","0    [document, :, Deep, Label, Distribution, Learn...   \n","1    [Convolutional, Neural, Networks, (, ConvNets,...   \n","2    [A, large, labeled, training, set, is, one, of...   \n","3    [However, ,, it, is, difficult, to, collect, s...   \n","4    [Fortunately, ,, there, is, ambiguous, informa...   \n","..                                                 ...   \n","606  [{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...   \n","607  [D, degree, from, Deakin, University, ,, Austr...   \n","608  [He, joined, the, School, of, Computer, Scienc...   \n","609  [He, has, authored, over, 50, refereed, papers...   \n","610  [His, research, interests, include, pattern, r...   \n","\n","                                                  tags  \\\n","0    [O, O, B-MTD, I-MTD, I-MTD, I-MTD, O, B-TSK, I...   \n","1    [B-MTD, I-MTD, I-MTD, I-MTD, I-MTD, I-MTD, O, ...   \n","2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n","3    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","4    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","..                                                 ...   \n","606  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","607                     [O, O, O, O, O, O, O, O, O, O]   \n","608  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","609  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","610         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n","\n","                                              ner_tags  \\\n","0                          [0, 0, 3, 4, 4, 4, 0, 1, 2]   \n","1    [3, 4, 4, 4, 4, 4, 0, 0, 0, 1, 2, 0, 0, 1, 2, ...   \n","2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","..                                                 ...   \n","606  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","607                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","608  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","609  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","610         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","\n","                                                tokens   id  \n","0    [document, :, Deep, Label, Distribution, Learn...    0  \n","1    [Convolutional, Neural, Networks, (, ConvNets,...    1  \n","2    [A, large, labeled, training, set, is, one, of...    2  \n","3    [However, ,, it, is, difficult, to, collect, s...    3  \n","4    [Fortunately, ,, there, is, ambiguous, informa...    4  \n","..                                                 ...  ...  \n","606  [{, IEEEbiography}, [], Xin, Geng, (, M’13, ),...  606  \n","607  [D, degree, from, Deakin, University, ,, Austr...  607  \n","608  [He, joined, the, School, of, Computer, Scienc...  608  \n","609  [He, has, authored, over, 50, refereed, papers...  609  \n","610  [His, research, interests, include, pattern, r...  610  \n","\n","[611 rows x 5 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data['tokens'] = [i for i in data['sentences']]\n","data['id'] = [i for i in data.index]\n","data"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:56.903005Z","iopub.status.busy":"2023-07-26T14:33:56.902470Z","iopub.status.idle":"2023-07-26T14:33:58.114866Z","shell.execute_reply":"2023-07-26T14:33:58.113580Z","shell.execute_reply.started":"2023-07-26T14:33:56.902963Z"},"executionInfo":{"elapsed":907,"status":"ok","timestamp":1686163852013,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"rYOyhj8N4473","outputId":"6cd50a24-e93e-41b8-fca3-3ef1aae7e4e0","trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'tokens', 'ner_tags'],\n","    num_rows: 611\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import Dataset\n","dataset = Dataset.from_pandas(data[['id','tokens','ner_tags']])\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"yE7NBuXR-Uov"},"source":["## Split dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:58.117232Z","iopub.status.busy":"2023-07-26T14:33:58.116592Z","iopub.status.idle":"2023-07-26T14:33:58.123115Z","shell.execute_reply":"2023-07-26T14:33:58.121945Z","shell.execute_reply.started":"2023-07-26T14:33:58.117197Z"},"id":"OQEQdvVW0fFA","trusted":true},"outputs":[],"source":["# LOAD OR TRAIN MODEL\n","TRAIN = 1 # 1 to TRAIN WEIGHTS or 0 to LOAD WEIGHTS\n","\n","# TRAIN/TEST SPLIT\n","TRAIN_TEST_SPLIT = 0.2\n","# TRAIN/VALIDATION SPLIT\n","TRAIN_VAL_SPLIT = 0.125\n","# Train:Test:Evaluation=7:2:1 (3.5:1:0.5)\n","\n","# RANDOM SEED FOR REPRODUCIBILITY\n","RANDOM_SEED = 42"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:58.125492Z","iopub.status.busy":"2023-07-26T14:33:58.124320Z","iopub.status.idle":"2023-07-26T14:33:59.234141Z","shell.execute_reply":"2023-07-26T14:33:59.232717Z","shell.execute_reply.started":"2023-07-26T14:33:58.125435Z"},"id":"3HRY0EAbz5n1","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","train_test = dataset.train_test_split(test_size=TRAIN_TEST_SPLIT)\n","train_valid = train_test['train'].train_test_split(test_size=TRAIN_VAL_SPLIT)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:59.236308Z","iopub.status.busy":"2023-07-26T14:33:59.235866Z","iopub.status.idle":"2023-07-26T14:33:59.246134Z","shell.execute_reply":"2023-07-26T14:33:59.244840Z","shell.execute_reply.started":"2023-07-26T14:33:59.236276Z"},"id":"q9bayYqwv6P_","trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 488\n","    })\n","    test: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 123\n","    })\n","    valid: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 61\n","    })\n","})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import DatasetDict\n","datasets = DatasetDict({\n","    'train': train_test['train'],\n","    'test': train_test['test'],\n","    'valid': train_valid['test']})\n","datasets"]},{"cell_type":"markdown","metadata":{"id":"aufcJ5iB-gpD"},"source":["# Train baselines on token classification"]},{"cell_type":"markdown","metadata":{"id":"9O5hDrWWoiqE"},"source":["## Build model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:59.400415Z","iopub.status.busy":"2023-07-26T14:33:59.399977Z","iopub.status.idle":"2023-07-26T14:33:59.415843Z","shell.execute_reply":"2023-07-26T14:33:59.414182Z","shell.execute_reply.started":"2023-07-26T14:33:59.400381Z"},"trusted":true},"outputs":[],"source":["MODELS={\"checkpoint\":[\"allenai/scibert_scivocab_uncased\",\"malteos/scincl\",\"allenai/specter2\", \"johngiorgi/declutr-sci-base\"],\n","       \"name\":[\"SciBERT\",\"SciNCL\",\"SPECTER\",\"DeCLTUR\",\"BioBERT\",\"SciFive\"]}\n","# change id to train on different baseline models\n","id=0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:33:59.417513Z","iopub.status.busy":"2023-07-26T14:33:59.417150Z","iopub.status.idle":"2023-07-26T14:34:02.086758Z","shell.execute_reply":"2023-07-26T14:34:02.085391Z","shell.execute_reply.started":"2023-07-26T14:33:59.417468Z"},"executionInfo":{"elapsed":6021,"status":"ok","timestamp":1686164411236,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"0R_jp3S-vtgC","outputId":"cd916fef-f033-42a1-ede9-29b75691c4fa","trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","if id==3:\n","    tokenizer = AutoTokenizer.from_pretrained(MODELS[\"checkpoint\"][id], add_prefix_space=True)\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(MODELS[\"checkpoint\"][id])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:02.099360Z","iopub.status.busy":"2023-07-26T14:34:02.098963Z","iopub.status.idle":"2023-07-26T14:34:02.124099Z","shell.execute_reply":"2023-07-26T14:34:02.122759Z","shell.execute_reply.started":"2023-07-26T14:34:02.099329Z"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1686164417179,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"6Sf-0zXgXgRK","trusted":true},"outputs":[],"source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True, max_length=512)\n","    labels = []\n","    for i, label in enumerate(examples[\"ner_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:02.126717Z","iopub.status.busy":"2023-07-26T14:34:02.126197Z","iopub.status.idle":"2023-07-26T14:34:02.145615Z","shell.execute_reply":"2023-07-26T14:34:02.144696Z","shell.execute_reply.started":"2023-07-26T14:34:02.126670Z"},"trusted":true},"outputs":[],"source":["def word_id_func(input_ids, print_labs=False):\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","    word_ids = []\n","    i=0\n","    spec_toks = ['[CLS]', '[SEP]', '[PAD]']\n","    for t in tokens:\n","        if t in spec_toks:\n","            word_ids.append(-100)\n","            print(t, i) if print_labs else None\n","        elif t.startswith('▁'):\n","            i += 1\n","            word_ids.append(i)\n","            print(t, i) if print_labs else None\n","        else:\n","            word_ids.append(i)\n","            print(t, i) if print_labs else None\n","        print(\"Total:\", i) if print_labs else None\n","    return word_ids\n","\n","def tokenize_and_align_labels_roberta(examples, label_all_tokens=False):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True,is_split_into_words=True, max_length=512)\n","    labels = []\n","    word_ids_list = []\n","    for input_ids in tokenized_inputs[\"input_ids\"]:\n","        wids = word_id_func(input_ids, print_labs=False)\n","        word_ids_list.append(wids)\n","    \n","    for i, label in enumerate(examples[\"ner_tags\"]):\n","        word_ids = word_ids_list[i]\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","            # ignored in the loss function.\n","            if word_idx == -100:\n","                label_ids.append(-100)\n","            #We set the label for the first token of each word.\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label[word_idx-1])\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            else:\n","                label_ids.append(label[word_idx-1] if label_all_tokens else -100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:02.147985Z","iopub.status.busy":"2023-07-26T14:34:02.147487Z","iopub.status.idle":"2023-07-26T14:34:02.404055Z","shell.execute_reply":"2023-07-26T14:34:02.402679Z","shell.execute_reply.started":"2023-07-26T14:34:02.147942Z"},"executionInfo":{"elapsed":1229,"status":"ok","timestamp":1686164420266,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"kY-sxt2sda-R","outputId":"496f6316-723a-4213-df03-85753693b0a2","trusted":true},"outputs":[],"source":["# tokenized_data= tokenize_and_align_labels(data)\n","if id==3:\n","    tokenized_datasets = datasets.map(tokenize_and_align_labels_roberta, batched=True)\n","else:\n","    tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"1NYaBBcI0HRt"},"source":["## Training"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:02.407133Z","iopub.status.busy":"2023-07-26T14:34:02.406187Z","iopub.status.idle":"2023-07-26T14:34:02.421206Z","shell.execute_reply":"2023-07-26T14:34:02.419230Z","shell.execute_reply.started":"2023-07-26T14:34:02.407082Z"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1686164443550,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"0frlM0OMIaVf","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_PROJECT=Thesis\n","env: WANDB_LOG_MODEL=True\n"]}],"source":["import torch\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(torch.cuda.get_device_name(device))\n","#     print(torch.cuda.current_device())\n","else:\n","    device ='cpu'\n","output_dir = output_path+'Models/cache'\n","# BATCH SIZE\n","# TRY 4, 8, 16, 32, 64, 128, 256. REDUCE IF OOM ERROR, HIGHER FOR TPUS\n","BATCH_SIZES = 4\n","# EPOCHS - TRANSFORMERS ARE TYPICALLY FINE-TUNED BETWEEN 1 AND 3 EPOCHS \n","EPOCHS = 10\n","# RANDOM SEED FOR REPRODUCIBILITY\n","RANDOM_SEED = 42\n","# SPECIFY THE WEIGHTS AND BIASES PROJECT NAME\n","%env WANDB_PROJECT = Thesis\n","# DETERMINE WHETHER TO SAVE THE MODEL IN THE 100GB OF FREE W&B STORAGE\n","%env WANDB_LOG_MODEL = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:02.424033Z","iopub.status.busy":"2023-07-26T14:34:02.423383Z","iopub.status.idle":"2023-07-26T14:34:17.162269Z","shell.execute_reply":"2023-07-26T14:34:17.161143Z","shell.execute_reply.started":"2023-07-26T14:34:02.423932Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForTokenClassification\n","model = AutoModelForTokenClassification.from_pretrained(MODELS[\"checkpoint\"][id], num_labels=len(label_list))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.164611Z","iopub.status.busy":"2023-07-26T14:34:17.163957Z","iopub.status.idle":"2023-07-26T14:34:17.180874Z","shell.execute_reply":"2023-07-26T14:34:17.179671Z","shell.execute_reply.started":"2023-07-26T14:34:17.164574Z"},"executionInfo":{"elapsed":3998,"status":"ok","timestamp":1686164448832,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"KP4olZyNmV5x","outputId":"a82a0e45-c31d-4956-f9df-a46d90281d02","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The maximum learning rate is:  3e-05\n"]}],"source":["# Training schedule\n","from transformers import AdamW, get_cosine_schedule_with_warmup\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","learning_rate = 0.0000075\n","lr_max = learning_rate * BATCH_SIZES\n","weight_decay = 0.05\n","print(\"The maximum learning rate is: \",lr_max)\n","num_train_samples = len(datasets[\"train\"])\n","warmup_ratio = 0.2 # Percentage of total steps to go from zero to max learning rate\n","num_cycles=0.8 # The cosine exponential rate\n","num_training_steps = num_train_samples*EPOCHS/BATCH_SIZES\n","num_warmup_steps = num_training_steps*warmup_ratio\n","#Optimizer\n","optimizer = torch.optim.AdamW(\n","                model.parameters(),\n","                lr=lr_max,\n","                weight_decay=weight_decay\n","            )\n","# Learning Rate Schedule\n","lr_sched = get_cosine_schedule_with_warmup(optimizer=optimizer,\n","                                   num_warmup_steps=num_warmup_steps,\n","                                   num_training_steps = num_training_steps,\n","                                   num_cycles=num_cycles)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.188467Z","iopub.status.busy":"2023-07-26T14:34:17.188046Z","iopub.status.idle":"2023-07-26T14:34:17.234664Z","shell.execute_reply":"2023-07-26T14:34:17.233588Z","shell.execute_reply.started":"2023-07-26T14:34:17.188435Z"},"trusted":true},"outputs":[],"source":["# Logging date for w&b\n","from datetime import date\n","today = date.today()\n","log_date = today.strftime(\"%d-%m-%Y\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.237313Z","iopub.status.busy":"2023-07-26T14:34:17.236516Z","iopub.status.idle":"2023-07-26T14:34:17.260986Z","shell.execute_reply":"2023-07-26T14:34:17.259720Z","shell.execute_reply.started":"2023-07-26T14:34:17.237267Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686164448833,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"dgBn0_kCCmtC","outputId":"d1ac3142-a253-4c13-e142-1492d76167ab","trusted":true},"outputs":[],"source":["from transformers import TrainingArguments\n","args = TrainingArguments(output_dir = output_dir,\n","                         evaluation_strategy = \"epoch\",\n","                         learning_rate=lr_max,\n","                         per_device_train_batch_size=BATCH_SIZES,\n","                         per_device_eval_batch_size=BATCH_SIZES,\n","                         num_train_epochs=EPOCHS,\n","                         weight_decay=weight_decay,\n","                         lr_scheduler_type = 'cosine',\n","                         warmup_ratio=warmup_ratio,\n","                         logging_strategy=\"epoch\",\n","                         save_strategy=\"epoch\",\n","                         seed=RANDOM_SEED,\n","                         report_to = 'wandb', # enable logging to W&B\n","                         run_name = MODELS[\"name\"][id] +\"-\"+log_date,\n","                         metric_for_best_model=\"f1\",\n","                         load_best_model_at_end = True,\n","                        )"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.263846Z","iopub.status.busy":"2023-07-26T14:34:17.262934Z","iopub.status.idle":"2023-07-26T14:34:17.280916Z","shell.execute_reply":"2023-07-26T14:34:17.279493Z","shell.execute_reply.started":"2023-07-26T14:34:17.263789Z"},"executionInfo":{"elapsed":908,"status":"ok","timestamp":1686164451722,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"b1AjeEQtTzjO","trusted":true},"outputs":[],"source":["from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import numpy as np\n","def compute_metrics(p):\n","    predictions, labels = p\n","    print(predictions,len(predictions))\n","    print(labels,len(labels))\n","    predictions = np.argmax(predictions, axis=2)\n","    print(predictions,type(predictions))\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)]\n","    print(type(true_predictions),len(true_predictions))\n","    print(type(true_labels),len(true_labels))\n","    # Define the metric parameters\n","    overall_precision = precision_score(true_labels, true_predictions, zero_division=1)\n","    overall_recall = recall_score(true_labels, true_predictions, zero_division=1)\n","    overall_f1 = f1_score(true_labels, true_predictions, zero_division=1)\n","    overall_accuracy = accuracy_score(true_labels, true_predictions)\n","    # Return a dictionary with the calculated metrics\n","    return {\n","        \"precision\": overall_precision,\n","        \"recall\": overall_recall,\n","        \"f1\": overall_f1,\n","        \"accuracy\": overall_accuracy,}"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.283723Z","iopub.status.busy":"2023-07-26T14:34:17.282862Z","iopub.status.idle":"2023-07-26T14:34:17.314423Z","shell.execute_reply":"2023-07-26T14:34:17.312721Z","shell.execute_reply.started":"2023-07-26T14:34:17.283677Z"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1686164454342,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"8A-IidfPURHd","trusted":true},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","data_collator = DataCollatorForTokenClassification(tokenizer)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.318064Z","iopub.status.busy":"2023-07-26T14:34:17.317046Z","iopub.status.idle":"2023-07-26T14:34:17.367021Z","shell.execute_reply":"2023-07-26T14:34:17.365741Z","shell.execute_reply.started":"2023-07-26T14:34:17.318013Z"},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1686164456890,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"C_9nKhP1S1ic","trusted":true},"outputs":[],"source":["from transformers import Trainer, TrainerCallback\n","class EmptyCacheCallback(TrainerCallback):\n","    def on_step_end(self, args, state, control, **kwargs):\n","        torch.cuda.empty_cache()\n","empty_cache_callback = EmptyCacheCallback()\n","\n","trainer = Trainer(\n","                model=model,\n","                args=args,\n","                train_dataset=tokenized_datasets[\"train\"],\n","                eval_dataset=tokenized_datasets[\"test\"],\n","                data_collator=data_collator,\n","                tokenizer=tokenizer,\n","                compute_metrics=compute_metrics,\n","                optimizers=(optimizer, lr_sched),\n","                callbacks=[empty_cache_callback],\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-26T14:34:17.369051Z","iopub.status.busy":"2023-07-26T14:34:17.368579Z","iopub.status.idle":"2023-07-26T14:37:56.628244Z","shell.execute_reply":"2023-07-26T14:37:56.626606Z","shell.execute_reply.started":"2023-07-26T14:34:17.369009Z"},"id":"ZFJzu3byrJ6R","outputId":"df2422ec-7ded-4359-dd4a-4457a95012b0","trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Evaluate based on the chosen epoch (usually best or last)\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.save_model(output_path+\"Models/\"+MODELS[\"name\"][id])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"h4TPs6o1_Qfl"},"source":["## Predictions on validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkmoKQ6UnAM8"},"outputs":[],"source":["# Load the model from the checkpoint\n","loaded_model = AutoModelForTokenClassification.from_pretrained(output_path+\"Models/\"+MODELS[\"name\"][id])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_trainer = Trainer(\n","    loaded_model,\n","    args,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# classification report\n","predictions, labels, _ = pred_trainer.predict(tokenized_datasets[\"valid\"])\n","predictions = np.argmax(predictions, axis=2)\n","\n","# Remove ignored index (special tokens)\n","true_predictions = [\n","    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","true_labels = [\n","    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","    ]\n","\n","# Generate the metrics and display\n","results = classification_report(true_labels, true_predictions, zero_division=1)\n","print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["check=123\n","datasets[\"valid\"][check]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Have a look at the predicted extracted data\n","check_pred = zip(datasets[\"valid\"][check]['tokens'], true_predictions[check])\n","for tup in check_pred:\n","    if tup[1] != 'O':\n","        print(tup)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare to the actual labels\n","check_true = zip(datasets[\"valid\"][check]['tokens'], true_labels[check])\n","for tup in check_true:\n","    if tup[1] != 'O':\n","        print(tup)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
