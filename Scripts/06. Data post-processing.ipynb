{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:04.871948Z","iopub.status.busy":"2023-09-03T12:30:04.871467Z","iopub.status.idle":"2023-09-03T12:30:17.235348Z","shell.execute_reply":"2023-09-03T12:30:17.233929Z","shell.execute_reply.started":"2023-09-03T12:30:04.871908Z"},"trusted":true},"outputs":[],"source":["!pip install --quiet tqdm "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:17.237994Z","iopub.status.busy":"2023-09-03T12:30:17.237587Z","iopub.status.idle":"2023-09-03T12:30:17.243143Z","shell.execute_reply":"2023-09-03T12:30:17.242137Z","shell.execute_reply.started":"2023-09-03T12:30:17.237950Z"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686825838296,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"RKgzdSu3eJ7o","trusted":true},"outputs":[],"source":["input_path='/kaggle/Input/'\n","output_path='/kaggle/working/'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:17.244693Z","iopub.status.busy":"2023-09-03T12:30:17.244391Z","iopub.status.idle":"2023-09-03T12:30:17.257835Z","shell.execute_reply":"2023-09-03T12:30:17.256650Z","shell.execute_reply.started":"2023-09-03T12:30:17.244667Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1686825838297,"user":{"displayName":"Xiao Wang","userId":"12080712970081279724"},"user_tz":-120},"id":"MGA2Ce-XePE8","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import pickle\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:17.260385Z","iopub.status.busy":"2023-09-03T12:30:17.259906Z","iopub.status.idle":"2023-09-03T12:30:18.756493Z","shell.execute_reply":"2023-09-03T12:30:18.755440Z","shell.execute_reply.started":"2023-09-03T12:30:17.260344Z"},"id":"_85C5U1bq27U","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /usr/share/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk import pos_tag\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:18.759417Z","iopub.status.busy":"2023-09-03T12:30:18.759023Z","iopub.status.idle":"2023-09-03T12:30:18.767866Z","shell.execute_reply":"2023-09-03T12:30:18.766889Z","shell.execute_reply.started":"2023-09-03T12:30:18.759386Z"},"trusted":true},"outputs":[],"source":["from nltk.corpus import stopwords\n","import string\n","stop_words=set(stopwords.words(\"english\"))\n","symbols=set(string.punctuation)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:18.769637Z","iopub.status.busy":"2023-09-03T12:30:18.769100Z","iopub.status.idle":"2023-09-03T12:30:18.780530Z","shell.execute_reply":"2023-09-03T12:30:18.779635Z","shell.execute_reply.started":"2023-09-03T12:30:18.769608Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'SciBERT'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["MODELS={\"name\":[\"SciBERT\",\"SciNCL\",\"SPECTER\",\"SciBERT-based\",\"SciNCL-based\",\"SPECTER-based\"]}\n","id=0\n","MODELS[\"name\"][id]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:18.782538Z","iopub.status.busy":"2023-09-03T12:30:18.781633Z","iopub.status.idle":"2023-09-03T12:30:18.805238Z","shell.execute_reply":"2023-09-03T12:30:18.804012Z","shell.execute_reply.started":"2023-09-03T12:30:18.782497Z"},"trusted":true},"outputs":[],"source":["with open(input_path+'Dictionary/domain_list.txt') as f:\n","    domain_list= [line.strip() for line in f]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:18.807424Z","iopub.status.busy":"2023-09-03T12:30:18.807048Z","iopub.status.idle":"2023-09-03T12:30:18.818990Z","shell.execute_reply":"2023-09-03T12:30:18.817960Z","shell.execute_reply.started":"2023-09-03T12:30:18.807393Z"},"trusted":true},"outputs":[],"source":["with open(input_path+'Dictionary/language_list.txt') as f:\n","    language_list= [line.strip() for line in f]"]},{"cell_type":"markdown","metadata":{},"source":["## load data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:30:18.821241Z","iopub.status.busy":"2023-09-03T12:30:18.820798Z","iopub.status.idle":"2023-09-03T12:31:04.059051Z","shell.execute_reply":"2023-09-03T12:31:04.057875Z","shell.execute_reply.started":"2023-09-03T12:30:18.821201Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ID</th>\n","      <th>true_predictions</th>\n","      <th>data_tuples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>34000</td>\n","      <td>[B-MTD, I-MTD, I-MTD, I-MTD, O, O, B-TSK, I-TS...</td>\n","      <td>[[FastIF:, B-MTD], [Scalable, I-MTD], [Influen...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>34000</td>\n","      <td>[O, O, B-MTD, O, O, O, O, O, O, B-MTD, I-MTD, ...</td>\n","      <td>[[FASTIF,, B-MTD], [influence, B-MTD], [functi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>34000</td>\n","      <td>[O, O, B-MTD, I-MTD, I-MTD, O, O, O, O, O, O, ...</td>\n","      <td>[[k-Nearest, B-MTD], [Neighbors, I-MTD], [(kNN...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>34000</td>\n","      <td>[O, O, O, O, O, B-MTD, I-MTD, I-MTD, O, O, O, ...</td>\n","      <td>[[fast, B-MTD], [influence, I-MTD], [functions...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>34000</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[[simulatability., B-MTD]]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>176610</th>\n","      <td>176610</td>\n","      <td>47999</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","      <td>[[back, B-TSK], [translation,, I-TSK], [back-t...</td>\n","    </tr>\n","    <tr>\n","      <th>176611</th>\n","      <td>176611</td>\n","      <td>47999</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-MTD,...</td>\n","      <td>[[synthetic, B-MTD], [data, I-MTD], [generatio...</td>\n","    </tr>\n","    <tr>\n","      <th>176614</th>\n","      <td>176614</td>\n","      <td>47999</td>\n","      <td>[O, O, O, O, O, O, O, O, B-MTD, I-MTD, I-MTD, ...</td>\n","      <td>[[Adam, B-MTD], [optimizer, I-MTD], [(Kingma, ...</td>\n","    </tr>\n","    <tr>\n","      <th>176616</th>\n","      <td>176616</td>\n","      <td>47999</td>\n","      <td>[O, O, O, B-MTD, I-MTD, O, O, O, O, O, O, O, O...</td>\n","      <td>[[fairseq, B-MTD], [10.2, I-MTD], [GPT, B-MTD]...</td>\n","    </tr>\n","    <tr>\n","      <th>176618</th>\n","      <td>176618</td>\n","      <td>47999</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, I-MTD, I-MTD, O...</td>\n","      <td>[[adam, I-MTD], [--adam-betas, I-MTD]]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6102407 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["            id     ID                                   true_predictions  \\\n","0            0  34000  [B-MTD, I-MTD, I-MTD, I-MTD, O, O, B-TSK, I-TS...   \n","2            2  34000  [O, O, B-MTD, O, O, O, O, O, O, B-MTD, I-MTD, ...   \n","3            3  34000  [O, O, B-MTD, I-MTD, I-MTD, O, O, O, O, O, O, ...   \n","5            5  34000  [O, O, O, O, O, B-MTD, I-MTD, I-MTD, O, O, O, ...   \n","6            6  34000  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","...        ...    ...                                                ...   \n","176610  176610  47999  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","176611  176611  47999  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-MTD,...   \n","176614  176614  47999  [O, O, O, O, O, O, O, O, B-MTD, I-MTD, I-MTD, ...   \n","176616  176616  47999  [O, O, O, B-MTD, I-MTD, O, O, O, O, O, O, O, O...   \n","176618  176618  47999  [O, O, O, O, O, O, O, O, O, O, I-MTD, I-MTD, O...   \n","\n","                                              data_tuples  \n","0       [[FastIF:, B-MTD], [Scalable, I-MTD], [Influen...  \n","2       [[FASTIF,, B-MTD], [influence, B-MTD], [functi...  \n","3       [[k-Nearest, B-MTD], [Neighbors, I-MTD], [(kNN...  \n","5       [[fast, B-MTD], [influence, I-MTD], [functions...  \n","6                              [[simulatability., B-MTD]]  \n","...                                                   ...  \n","176610  [[back, B-TSK], [translation,, I-TSK], [back-t...  \n","176611  [[synthetic, B-MTD], [data, I-MTD], [generatio...  \n","176614  [[Adam, B-MTD], [optimizer, I-MTD], [(Kingma, ...  \n","176616  [[fairseq, B-MTD], [10.2, I-MTD], [GPT, B-MTD]...  \n","176618             [[adam, I-MTD], [--adam-betas, I-MTD]]  \n","\n","[6102407 rows x 4 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["folder_path=input_path+\"Results/\"+MODELS[\"name\"][id]\n","data=pd.DataFrame()\n","for filename in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, filename)\n","    df= pd.read_parquet(file_path)\n","    data=pd.concat([data,df])\n","data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:04.061427Z","iopub.status.busy":"2023-09-03T12:31:04.060431Z","iopub.status.idle":"2023-09-03T12:31:07.737536Z","shell.execute_reply":"2023-09-03T12:31:07.736206Z","shell.execute_reply.started":"2023-09-03T12:31:04.061390Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ID</th>\n","      <th>true_predictions</th>\n","      <th>data_tuples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>141</td>\n","      <td>0</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n","      <td>[[Taiwan, B-DST], [corpus., I-DST]]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>77</td>\n","      <td>0</td>\n","      <td>[O, O, O, B-TSK, I-TSK, I-TSK, O, O, O, O, O, ...</td>\n","      <td>[[data, B-TSK], [sparseness, I-TSK], [problem,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>78</td>\n","      <td>0</td>\n","      <td>[O, B-MTD, I-MTD, I-MTD, O, O, O, O, O]</td>\n","      <td>[[generalization, B-MTD], [process, I-MTD], [r...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>79</td>\n","      <td>0</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, B-TSK, I-TSK, O...</td>\n","      <td>[[characterization, B-TSK], [since, I-TSK]]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>81</td>\n","      <td>0</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, B-MTD, I-MTD, O...</td>\n","      <td>[[TFIDF, B-MTD], [value, I-MTD]]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6041389</th>\n","      <td>30920</td>\n","      <td>59202</td>\n","      <td>[O, O, B-TSK, I-TSK, I-TSK, I-TSK, O, O, O, O,...</td>\n","      <td>[[real, B-TSK], [world, I-TSK], [dialogue, I-T...</td>\n","    </tr>\n","    <tr>\n","      <th>6041390</th>\n","      <td>30919</td>\n","      <td>59202</td>\n","      <td>[O, O, O, B-MTD, I-MTD, O, O, O, O, O, O, O, B...</td>\n","      <td>[[POMDP, B-MTD], [algorithms, I-MTD], [policy,...</td>\n","    </tr>\n","    <tr>\n","      <th>6041391</th>\n","      <td>30918</td>\n","      <td>59202</td>\n","      <td>[O, O, B-TSK, I-TSK, I-TSK, O, B-MTD, I-MTD, I...</td>\n","      <td>[[speech, B-TSK], [recognition, I-TSK], [degra...</td>\n","    </tr>\n","    <tr>\n","      <th>6041392</th>\n","      <td>30930</td>\n","      <td>59202</td>\n","      <td>[O, O, O, O, O, B-MTD, I-MTD, O, O, O, O, O, O...</td>\n","      <td>[[machine, B-MTD], [interpreter, I-MTD]]</td>\n","    </tr>\n","    <tr>\n","      <th>6041393</th>\n","      <td>31028</td>\n","      <td>59202</td>\n","      <td>[O, O, O, O, O, O, O, O, B-MTD, I-MTD, O, O, O...</td>\n","      <td>[[POMDP, B-MTD], [code, I-MTD]]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6041394 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["            id     ID                                   true_predictions  \\\n","0          141      0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...   \n","1           77      0  [O, O, O, B-TSK, I-TSK, I-TSK, O, O, O, O, O, ...   \n","2           78      0            [O, B-MTD, I-MTD, I-MTD, O, O, O, O, O]   \n","3           79      0  [O, O, O, O, O, O, O, O, O, O, B-TSK, I-TSK, O...   \n","4           81      0  [O, O, O, O, O, O, O, O, O, O, B-MTD, I-MTD, O...   \n","...        ...    ...                                                ...   \n","6041389  30920  59202  [O, O, B-TSK, I-TSK, I-TSK, I-TSK, O, O, O, O,...   \n","6041390  30919  59202  [O, O, O, B-MTD, I-MTD, O, O, O, O, O, O, O, B...   \n","6041391  30918  59202  [O, O, B-TSK, I-TSK, I-TSK, O, B-MTD, I-MTD, I...   \n","6041392  30930  59202  [O, O, O, O, O, B-MTD, I-MTD, O, O, O, O, O, O...   \n","6041393  31028  59202  [O, O, O, O, O, O, O, O, B-MTD, I-MTD, O, O, O...   \n","\n","                                               data_tuples  \n","0                      [[Taiwan, B-DST], [corpus., I-DST]]  \n","1        [[data, B-TSK], [sparseness, I-TSK], [problem,...  \n","2        [[generalization, B-MTD], [process, I-MTD], [r...  \n","3              [[characterization, B-TSK], [since, I-TSK]]  \n","4                         [[TFIDF, B-MTD], [value, I-MTD]]  \n","...                                                    ...  \n","6041389  [[real, B-TSK], [world, I-TSK], [dialogue, I-T...  \n","6041390  [[POMDP, B-MTD], [algorithms, I-MTD], [policy,...  \n","6041391  [[speech, B-TSK], [recognition, I-TSK], [degra...  \n","6041392           [[machine, B-MTD], [interpreter, I-MTD]]  \n","6041393                    [[POMDP, B-MTD], [code, I-MTD]]  \n","\n","[6041394 rows x 4 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data=data[data['data_tuples'].str.len() != 0]\n","data=data.sort_values(by=['ID']).reset_index(drop=True)\n","data['id'] =data.groupby('ID').cumcount()\n","data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:08.562988Z","iopub.status.busy":"2023-09-03T12:31:08.562620Z","iopub.status.idle":"2023-09-03T12:31:44.513751Z","shell.execute_reply":"2023-09-03T12:31:44.512608Z","shell.execute_reply.started":"2023-09-03T12:31:08.562956Z"},"trusted":true},"outputs":[],"source":["data[[\"ID\",\"id\",\"true_predictions\",\"data_tuples\"]].to_parquet(output_path+'Results_'+MODELS[\"name\"][id]+'.parquet')"]},{"cell_type":"markdown","metadata":{},"source":["## Merged workflow for post-processing"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:44.734921Z","iopub.status.busy":"2023-09-03T12:31:44.733743Z","iopub.status.idle":"2023-09-03T12:31:45.446830Z","shell.execute_reply":"2023-09-03T12:31:45.445633Z","shell.execute_reply.started":"2023-09-03T12:31:44.734873Z"},"trusted":true},"outputs":[],"source":["import re\n","def remove_symbols(text):\n","    # Define the pattern to match symbols (non-alphanumeric characters)\n","    pattern = r'[^a-zA-Z\\s-]'\n","    return re.sub(pattern, '', text)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:45.449363Z","iopub.status.busy":"2023-09-03T12:31:45.448320Z","iopub.status.idle":"2023-09-03T12:31:45.464692Z","shell.execute_reply":"2023-09-03T12:31:45.463563Z","shell.execute_reply.started":"2023-09-03T12:31:45.449321Z"},"trusted":true},"outputs":[],"source":["def extract_keyphrases(output):\n","    keyphrases = {\n","        \"TSK\": [],\n","        \"MTD\": [],\n","        \"DST\":[]\n","    }\n","\n","    current_phrase = []\n","    current_tag = None\n","\n","    for token, tag in output:\n","        if tag.startswith(\"B-\"):\n","            # If the tag is the beginning of a new keyphrase, add the current phrase to the list\n","            if current_tag is not None:\n","                keyphrases[current_tag].append(\" \".join(current_phrase))\n","                current_phrase = []\n","            # Start a new keyphrase with the current token\n","            current_phrase.append(token.lower())\n","            current_tag = tag.split(\"-\")[1]\n","        elif tag.startswith(\"I-\"):\n","            # If the tag is inside an existing keyphrase, append the current token to the phrase\n","            current_phrase.append(token.lower())\n","        else:\n","            # If the tag is not part of a keyphrase, reset the current phrase and tag\n","            if current_tag is not None:\n","                keyphrases[current_tag].append(\" \".join(current_phrase))\n","                current_phrase = []\n","                current_tag = None\n","\n","    # Add the last keyphrase if it exists\n","    if current_tag is not None:\n","        keyphrases[current_tag].append(\" \".join(current_phrase))\n","\n","    return keyphrases"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:38:55.114009Z","iopub.status.busy":"2023-09-03T12:38:55.113535Z","iopub.status.idle":"2023-09-03T12:38:55.122725Z","shell.execute_reply":"2023-09-03T12:38:55.121543Z","shell.execute_reply.started":"2023-09-03T12:38:55.113973Z"},"trusted":true},"outputs":[],"source":["# filter out stop_words\n","def filter_token(result_list,stop_words):\n","    # Remove stop words, special symbols and numbers \n","    target = [(token,label) for token,label in result_list if (token.lower() not in stop_words)]\n","    # Filter out non-noun, non-adjective, non-adverb, and non-verb words\n","    pos_tags = {'NN', 'NNS', 'NNP', 'NNPS',  # Nouns\n","                'JJ', 'JJR', 'JJS',       # Adjectives\n","                'RB', 'RBR', 'RBS',       # Adverbs\n","                'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}  # Verbs\n","    tagged_tokens = []\n","    for (token,label) in target:\n","        try:\n","            tagged_token = pos_tag([token])[0]\n","            tagged_tokens.append((tagged_token,label))\n","        except IndexError:\n","            # If the token cannot be tagged, include it as is\n","            tagged_tokens.append(((token,label), ''))\n","    filtered_tokens = [(token, label) for ((token, pos),label) in tagged_tokens if pos in pos_tags or not pos]\n","    return filtered_tokens\n","#     return target"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:45.486439Z","iopub.status.busy":"2023-09-03T12:31:45.486095Z","iopub.status.idle":"2023-09-03T12:31:45.503185Z","shell.execute_reply":"2023-09-03T12:31:45.502085Z","shell.execute_reply.started":"2023-09-03T12:31:45.486409Z"},"trusted":true},"outputs":[],"source":["def remove_subsets(input_dict):\n","    output_dict = {}\n","    for key, value in input_dict.items():\n","        final_values = []\n","        for item1 in value:\n","            is_subset = False\n","            for item2 in value:\n","                if item1 != item2 and all(word in item2.split() for word in item1.split()):\n","                    is_subset = True\n","                    break\n","            if not is_subset:\n","                final_values.append(item1)\n","        output_dict[key] = final_values\n","    return output_dict"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:45.505496Z","iopub.status.busy":"2023-09-03T12:31:45.505111Z","iopub.status.idle":"2023-09-03T12:31:45.516785Z","shell.execute_reply":"2023-09-03T12:31:45.515754Z","shell.execute_reply.started":"2023-09-03T12:31:45.505463Z"},"trusted":true},"outputs":[],"source":["def search_domain(text_list, domain_list):\n","    domain_key = []\n","    for text in text_list:\n","        for domain in domain_list:\n","            matches = re.findall(domain.lower(), text.lower())\n","            domain_key.extend(matches)\n","    domain_key = list(domain_key)\n","    return domain_key"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:45.518603Z","iopub.status.busy":"2023-09-03T12:31:45.518015Z","iopub.status.idle":"2023-09-03T12:31:45.533270Z","shell.execute_reply":"2023-09-03T12:31:45.532401Z","shell.execute_reply.started":"2023-09-03T12:31:45.518569Z"},"trusted":true},"outputs":[],"source":["def search_language(text_list, language_list):\n","    language_key = []\n","    for text in text_list:\n","        for language in language_list:\n","            # full case match\n","            pattern = r'\\b' + re.escape(language) + r'\\b'\n","            if re.search(pattern, text, re.IGNORECASE):\n","                language_key.append(language)\n","#     language_key = list(set(language_key))\n","    language_key = list(language_key)\n","    return language_key"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:45.534957Z","iopub.status.busy":"2023-09-03T12:31:45.534619Z","iopub.status.idle":"2023-09-03T12:31:45.553640Z","shell.execute_reply":"2023-09-03T12:31:45.552534Z","shell.execute_reply.started":"2023-09-03T12:31:45.534928Z"},"trusted":true},"outputs":[],"source":["def calculate_precision(dict1, dict2):\n","    precision = {}\n","    for key in dict1.keys():\n","        if key in dict2.keys():\n","            if dict2[key] <dict1[key]:\n","                if dict1[key]!=0:\n","                    precision[key] = float(dict2[key]) / float(dict1[key])\n","            else:\n","                if dict2[key]!=0:\n","                    precision[key] = float(dict1[key]) / float(dict2[key])\n","                else:\n","                    precision[key] =1\n","    return precision"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:31:45.555636Z","iopub.status.busy":"2023-09-03T12:31:45.554946Z","iopub.status.idle":"2023-09-03T12:31:45.577583Z","shell.execute_reply":"2023-09-03T12:31:45.576662Z","shell.execute_reply.started":"2023-09-03T12:31:45.555601Z"},"trusted":true},"outputs":[],"source":["import pickle\n","with open(input_path+\"Data/100_random_ids.pkl\", \"rb\") as file:\n","    sampled_ids=pickle.load(file)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-09-03T12:38:59.333040Z","iopub.status.busy":"2023-09-03T12:38:59.332278Z","iopub.status.idle":"2023-09-03T12:39:27.676329Z","shell.execute_reply":"2023-09-03T12:39:27.675237Z","shell.execute_reply.started":"2023-09-03T12:38:59.333005Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:28<00:00,  3.53it/s]\n"]}],"source":["# process all the acl papers takes around 2 hours\n","from tqdm import tqdm\n","post_doc={}\n","micro_precisions={}\n","ID_list=data.ID.unique()\n","for _, ID in tqdm(enumerate(sampled_ids), total=len(sampled_ids)):\n","# for _, ID in tqdm(enumerate(ID_list), total=len(ID_list)):\n","    doc=[i for item in data[data['ID'] == ID]['data_tuples'] for i in item]\n","    new_output=[]\n","    # remove special remarks\n","    for item in doc:\n","        if len(remove_symbols(item[0]))>0:\n","            new_output.append((remove_symbols(item[0]),item[1]))\n","    # filter out stopwords\n","    new_output=filter_token(new_output,stop_words)\n","    # transform into key-value pairs\n","    keyphrases=extract_keyphrases(new_output)\n","    # extract domain and language\n","    keyphrases[\"DOM\"]=[]\n","    keyphrases[\"LAN\"]=[]\n","    for item in keyphrases.values():\n","        keyphrases.update({\"DOM\":keyphrases[\"DOM\"]+search_domain(item,domain_list)})\n","        keyphrases.update({\"LAN\":keyphrases[\"LAN\"]+search_language(item,language_list)})\n","    # remove the duplicates\n","    new_keyphrases ={}\n","    for key, value in keyphrases.items():\n","        unique_values = list(set(value))\n","        new_keyphrases[key] = unique_values\n","    # remove the subsets\n","    new_keyphrases = remove_subsets(new_keyphrases)\n","    lengths1 = {key: len(value) for key, value in keyphrases.items()}\n","    lengths2 = {key: len(value) for key, value in new_keyphrases.items()}\n","    micro_precision = calculate_precision(lengths1, lengths2)\n","    micro_precisions.update({ID:micro_precision})\n","    # special handle of language and domain\n","    if len(new_keyphrases[\"LAN\"]) == 0:\n","        new_keyphrases[\"LAN\"]=[\"English\"]\n","    if len(new_keyphrases[\"DOM\"]) == 0:\n","        new_keyphrases[\"DOM\"]=[\"Computer Science\"]\n","    # sorted\n","    new_keyphrases = {key: sorted(value) for key, value in new_keyphrases.items()}\n","    post_doc.update({ID:new_keyphrases})"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T13:30:35.201248Z","iopub.status.busy":"2023-08-23T13:30:35.200627Z","iopub.status.idle":"2023-08-23T13:30:35.211597Z","shell.execute_reply":"2023-08-23T13:30:35.210117Z","shell.execute_reply.started":"2023-08-23T13:30:35.201215Z"},"trusted":true},"outputs":[],"source":["import pickle\n","with open(output_path+\"Eval/keyphrases_\"+MODELS[\"name\"][id]+\".pkl\", \"wb\") as file:\n","    pickle.dump(post_doc, file)\n","with open(output_path+\"Eval/precisions_\"+MODELS[\"name\"][id]+\".pkl\", \"wb\") as file:\n","    pickle.dump(micro_precisions, file)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
