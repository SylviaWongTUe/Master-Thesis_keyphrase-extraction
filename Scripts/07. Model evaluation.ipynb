{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T14:16:04.722957Z","iopub.status.busy":"2023-09-12T14:16:04.722446Z","iopub.status.idle":"2023-09-12T14:16:04.757593Z","shell.execute_reply":"2023-09-12T14:16:04.755866Z","shell.execute_reply.started":"2023-09-12T14:16:04.722902Z"},"trusted":true},"outputs":[],"source":["input_path='/kaggle/Input/'\n","output_path='/kaggle/working/'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T14:16:05.748467Z","iopub.status.busy":"2023-09-12T14:16:05.747795Z","iopub.status.idle":"2023-09-12T14:16:05.753403Z","shell.execute_reply":"2023-09-12T14:16:05.752231Z","shell.execute_reply.started":"2023-09-12T14:16:05.748425Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import pickle\n","import os\n","import csv\n","import math"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T14:16:06.825480Z","iopub.status.busy":"2023-09-12T14:16:06.825065Z","iopub.status.idle":"2023-09-12T14:16:06.832746Z","shell.execute_reply":"2023-09-12T14:16:06.831901Z","shell.execute_reply.started":"2023-09-12T14:16:06.825444Z"},"trusted":true},"outputs":[],"source":["with open(input_path+\"Data/100_random_ids.pkl\", \"rb\") as file:\n","    sampled_ids=pickle.load(file)"]},{"cell_type":"markdown","metadata":{},"source":["## merged workflow"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T15:15:02.821823Z","iopub.status.busy":"2023-09-12T15:15:02.821377Z","iopub.status.idle":"2023-09-12T15:15:02.830226Z","shell.execute_reply":"2023-09-12T15:15:02.829066Z","shell.execute_reply.started":"2023-09-12T15:15:02.821790Z"},"trusted":true},"outputs":[],"source":["def calculate_f1(df_recall,df_precision):\n","    f1_dict={}\n","    for name in name_list:\n","        f1=0\n","        for id in sampled_ids:\n","            if df_recall[name][id] + df_precision[name][id] > 0:\n","                f1+= float(2 * (df_recall[name][id] * df_precision[name][id]) / (df_recall[name][id] + df_precision[name][id]))\n","            else:\n","                # Handle the case when the denominator is zero\n","                f1+=0.0\n","        f1_dict.update({name:round(f1/len(sampled_ids),3)})\n","    return f1_dict"]},{"cell_type":"code","execution_count":233,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T16:57:36.807101Z","iopub.status.busy":"2023-09-12T16:57:36.806713Z","iopub.status.idle":"2023-09-12T16:57:43.099776Z","shell.execute_reply":"2023-09-12T16:57:43.098594Z","shell.execute_reply.started":"2023-09-12T16:57:36.807070Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------SciBERT--------------------\n","micro_F1:\n","{'Task': 0.67, 'Method': 0.681, 'Dataset': 0.676, 'Domain': 0.67, 'Language': 0.55}\n","macro_F1:\n","0.649\n","--------------------SciNCL--------------------\n","micro_F1:\n","{'Task': 0.63, 'Method': 0.643, 'Dataset': 0.487, 'Domain': 0.663, 'Language': 0.588}\n","macro_F1:\n","0.602\n","--------------------SPECTER--------------------\n","micro_F1:\n","{'Task': 0.636, 'Method': 0.655, 'Dataset': 0.521, 'Domain': 0.667, 'Language': 0.59}\n","macro_F1:\n","0.614\n","--------------------SciBERT-based--------------------\n","micro_F1:\n","{'Task': 0.791, 'Method': 0.795, 'Dataset': 0.746, 'Domain': 0.758, 'Language': 0.652}\n","macro_F1:\n","0.748\n","--------------------SciNCL-based--------------------\n","micro_F1:\n","{'Task': 0.772, 'Method': 0.748, 'Dataset': 0.654, 'Domain': 0.77, 'Language': 0.645}\n","macro_F1:\n","0.718\n","--------------------SPECTER-based--------------------\n","micro_F1:\n","{'Task': 0.777, 'Method': 0.779, 'Dataset': 0.711, 'Domain': 0.754, 'Language': 0.646}\n","macro_F1:\n","0.733\n"]}],"source":["MODELS={\"name\":[\"SciBERT\",\"SciNCL\",\"SPECTER\",\"SciBERT-based\",\"SciNCL-based\",\"SPECTER-based\"]}\n","\n","for id in range(len(MODELS[\"name\"])):\n","    print(\"--------------------\"+str(MODELS[\"name\"][id])+\"--------------------\")\n","    # load and process the sampled dataset\n","    with open(input_path+\"Data/100_random_ids.pkl\", \"rb\") as file:\n","        sampled_ids=pickle.load(file)\n","    with open(input_path+\"Eval/keyphrases_\"+MODELS[\"name\"][id]+\".pkl\", \"rb\") as file:\n","        keyphrases=pickle.load(file)\n","    sampled_keyphrases = {key: value for key, value in keyphrases.items() if key in sampled_ids}\n","    df_sampled=pd.DataFrame()\n","    df_sampled = pd.DataFrame.from_dict(sampled_keyphrases, orient='index').rename(columns={\"TSK\": \"Task\", \"MTD\": \"Method\",\"DST\":\"Dataset\",\"DOM\":\"Domain\",\"LAN\":\"Language\"})\n","    df_sampled.insert(0, \"ID\", sampled_keyphrases.keys())\n","    df_sampled=df_sampled.sort_values('ID').reset_index(drop=True)\n","\n","    # load the labeled data results\n","    data_labeled=pd.read_csv(input_path+\"Eval/keyphrases_100_labeled.csv\")\n","\n","    # evaluate the model\n","    name_list1=[\"Task\",\"Method\",\"Dataset\"]\n","    name_list2=[\"Domain\",\"Language\"]\n","    name_list = name_list1 + name_list2\n","    df_recall=pd.DataFrame(np.zeros((len(df_sampled), len(name_list))), \n","                          columns=[str(column_name) for column_name in name_list])\n","    for i in range(len(df_sampled)):\n","        for j in name_list1:\n","            score=0\n","            sum_list=[]\n","            list1=df_sampled[j][i]\n","            list2=data_labeled[j][i].split(', ')\n","            for item in list2:\n","                for char in item.split(' '):\n","                    sum_list.append(char)\n","            for item1 in list1:\n","                flag=0\n","                for item2 in list2:\n","                    if item1 == item2:\n","                        score+=1\n","                        flag=1\n","                    elif item1 in item2 or item2 in item1:\n","                        score+=min(len(item1),len(item2))/max(len(item1),len(item2))\n","                        flag=1\n","                if flag==0:\n","                    for char in item1.split(' '):\n","                        frequency = sum(1 for s in sum_list if s == char)\n","                        score += frequency/len(sum_list)\n","            df_recall[j][i]=score/len(list2)\n","        for j in name_list2:\n","            score=0\n","            set1 = set(list(df_sampled[j][i]))\n","            set2 = set(list(data_labeled[j][i].split(', ')))\n","            common_items = set1.intersection(set2)\n","            df_recall[j][i]=len(common_items)/len(set2)\n","\n","    df_recall.index=df_sampled[\"ID\"]\n","\n","    # load the precisions data that is generated togehter with the post-processed data in the 06 code\n","    with open(input_path+\"Eval/precisions_\"+MODELS[\"name\"][id]+\".pkl\", \"rb\") as file:\n","        micro_precisions=pickle.load(file)\n","    df_precision = pd.DataFrame.from_dict(micro_precisions, orient='index')\n","    df_precision = df_precision.rename(columns={old_name: new_name for old_name, new_name in zip(df_precision.columns, name_list)})\n","    df_precision = df_precision.loc[sampled_ids].sort_index()\n","\n","    # calculate the F1 scores\n","    print(\"micro_F1:\")\n","    f1=calculate_f1(df_recall,df_precision)\n","    print(f1)\n","    print(\"macro_F1:\")\n","    print(round(sum(list(f1.values()))/len(f1.keys()),3))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
